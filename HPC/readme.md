### Float4 向量化访存到底带来了什么？
1. 对于访存单元而言，需要发射的访存指令更少了。假设用的是正常的float，那么读取4个float的话，需要发射4条LD.E指令。而使用float4的话，只需要发射一条LD.E.128指令。那直观上性能自然更优。但需要说明的是，在Nvidia的GPU中，由于SIMT架构是通过切换warp来掩盖访存的延时，所以并不代表着4个cycle发射4条指令就比1个cycle发射1条指令慢4倍，大部分的时间其实都是在等待访存单元把数据拿回来，而真正访存的时间，不管是去L1还是L2拿数，cache line都是128Byte。float和float4都是一样。对于一个warp而言，如果32个线程想要去拿128个数，不管float还是float4，都得变成4次对cache line的读取，当然，如果仅仅是拷贝，这个cache line还不一定命中。如果到了global mem中去读，从硬件的角度而言，访存端口也是一样，并不会因为float4就能够获得更多的端口读数。所以结论是，float4会更快，但是快得不多。

2. 对于指令cache而言，所需要的指令更少了，那么icache不命中的概率就会减少很多。我们假设一个场景，对于一段核心代码，volta架构有12KB的L0 指令cache，一条指令需要128bit，那么最多可以容纳768条SASS指令，对于sgemm中的核心循环，假设取12行12列，组成12x12=144条FFMA指令，循环展开6次，144x6=576条指令，一共有(12+12)*6 = 144个数需要load，如果用float则需要144条指令，那么计算和访存一共有720条指令，再加一些其他的指令，很容易导致指令cache放不下，性能有所损失。如果用float4的话，则需要144/4 = 36条指令，总共612条指令，指令cache肯定能放得下。

当然，转成float4也会产生一些负面的影响，首先是所采用的寄存器更多了，寄存器资源被占用多了之后，SM中能够并发的warp数量会有所减少。此外，如果本身程序的并行粒度就不太够，使用float4的话，所使用的block数量减少，warp数量减少，性能也会有一定的影响。所以如果是并行粒度本身不太够的情况下，还是需要谨慎地考虑是否采用float4这样的向量化数据。


### SIMT和SIMD的区别
#### 从程序员的角度来看，SIMT和SIMD在编程模型和代码优化上也存在一些差异:

1. SIMT采用的是线程模型,程序员主要针对线程块(block)和线程(thread)的组织来优化,利用更多线程来隐藏延迟,提高并行粒度。SIMD采用数据并行模型,程序员需要通过向量化、循环展开等方式提高数据级别的并行性。
2. SIMT线程间可以使用 barrier 同步或者 atomic 操作通信,而SIMD通常需要程序员明确的使用缓存对齐,避免向量化时的内存数据冲突。
3. SIMT编程可以不需要考虑硬件特性,由编译器自动优化生成设备代码。而SIMD需要充分考虑目标硬件的特点,比如向量寄存器长度,最大带宽等。
4. SIMT更适合不规则,动态的代码,程序员主要负责算法和组织并行框架。SIMD对代码结构要求更高,程序员需要关注每一条指令是否可以向量化。
5. SIMT对程序员的要求较低,学习曲线更平稳。而SIMD编程门槛更高,需要较强的并行编程能力。
6. SIMT可移植性更好,同一代码可以在不同GPU架构上运行。而SIMD优化往往跟特定指令集严密相关。
7. SIMT调试更简单,可以在CUDA中设置断点,打印日志。而SIMD需要更底层的调试。

#### 从指令集的角度来看,SIMT和SIMD主要有以下几点区别:

1. 指令并行粒度不同。SIMD的指令通常并行度较小,如128bit或256bit,一次执行几个单精度浮点运算。而SIMT可组合更多线程,一次同步执行数百条指令。
2. 寻址模式不同。SIMD使用连续的向量寻址,同一指令操作一个向量/矩阵。SIMT允许各线程独立寻址,访问不同地址空间。
3. 流水线不同。SIMD采用传统的重叠流水线,提高单指令吞吐。SIMT使用更宽的流水线,同时执行多指令,需要更复杂的调度和同步。
4. 指令集特性不同。SIMD提供丰富的向量计算/转换指令。SIMT提供线程同步,通信原语。
5. 控制流处理不同。SIMD中的所有执行单元必须严格同步。SIMT支持线程级控制流,可执行不同路径。
6. 编译实现不同。SIMD由标准编译器优化。SIMT需要专门的设备编译器,处理复杂的线程调度和变量映射。
7. 硬件实现不同。SIMD扩展现有指令集和流水线。SIMT需要专门的多处理器和调度器。


